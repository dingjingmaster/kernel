# The kernel and character set encodings

这一切都始于一个JFS bug报告。当用户空间向JFS文件系统传递以UTF-8格式编码的文件名时，它似乎会感到不安。它不是用给定的名称创建或打开文件，而是放弃并返回EINVAL。修复该问题的补丁已经发布，但由此产生的讨论花费了相当长的时间来解决。

JFS有一个“iocharset”选项，可用于在挂载时显式声明正在使用哪种字符编码。在linux-kernel中也有人要求将这个选项添加到其他文件系统中。然而，由于几个原因，这个想法被强烈否决了。其中之一是多个用户可以同时在同一个文件系统上使用不同的字符编码；整个文件系统的全局选项显然无法解决这种情况。

然而，真正的原因是，执行字符集转换需要内核解释从用户空间传递给它的文件名字符串。内核黑客非常抵制任何此类政策的强加；这将违背Unix几十年的传统。正式地说，内核没有关于文件名、内容或其他任何东西使用哪个字符集的策略。在每种情况下，内核看到的都只是一个字节流。

也就是说，内核确实有一些关于文件名的策略：它们使用“/”作为目录分隔符，并以NULL字节结束。此策略排除使用许多有时用于表示非ascii字符的编码；固定宽度的宽编码都倾向于使用大量包含零的字节。实际上，表示ASCII字符集以外的字符的唯一实际选择是iso-8859-1（它允许表示许多欧洲大陆语言中使用的字符）和UTF-8，后者几乎可以编码任何东西。

UTF-8相对容易使用；对于美国用户来说，它看起来就像ASCII，但它可以处理更广泛的字符，同时不会破坏（大多数）使用传统C字符串的代码。因此，人们经常说UTF-8是Linux内核使用的编码。然而，这种说法是错误的：Linux不使用任何特定的编码。如果用户空间使用UTF-8表示扩展字符，那么一切都可以正常工作。但没有什么能强迫用户空间以这种方式工作。

这种方法将策略排除在内核之外，但是一些开发人员对此并不完全满意。缺乏策略会在很多方面导致用户空间的混乱。例如，如果用户创建了一个名为WéîrdÑàmë的文件，那么该名称可以在文件系统中以多种方式表示。根据用户空间的配置方式，它可以选择iso-8859-1或UTF-8；根据选择的不同，该名称的编码将会有很大的不同。不同的用户空间将来可能会以不同的方式解释文件名，从而导致文件名不可读并使用户感到困惑。内核缺乏自己的字符编码策略，因此无法阻止这种情况的发生。

对字符集的混淆也会促进安全漏洞的产生；如果以意想不到的编码方式给出了邪恶字符，那么试图清理文件名的代码可能会失败。期望使用UTF-8的代码在处理Linux内核时也必须小心，因为内核本身不会努力确保任何字符串实际上是合法的UTF-8编码。

为了使情况更加复杂，Andrew Tridgell发表了他认为内核必须采用特定字符编码的另一个原因：大小写不敏感。Tridge说:

```
原因是我认为Linux内核最终将需要有效地支持不区分大小写的用户空间策略，而执行不区分大小写的文件名操作的唯一方法是将这些字节流解释为特定的编码。
```
不用说，在内核中实现不区分大小写的文件系统操作的想法并不是特别流行。没有多少内核黑客想要使文件系统代码复杂化，以实现他们认为是一个坏的Windows特性。还有其他困难：在不同的语言中，不区分大小写的匹配必须以不同的方式进行。最终的结果是，不区分大小写的查找不太可能很快进入内核。

但是，Linus并不反对尝试帮助Samba和其他希望实现不区分大小写行为的应用程序。他提出了一个新的“magic_open()”接口，该接口将使用户更容易执行不区分大小写的查找，而无需在内核中实际执行该工作。这个接口可能需要做很多工作才能满足Samba开发人员的需要，但是从它派生出来的一些东西可能会出现在2.7开发系列中。

同时，内核似乎不太可能很快采用任何形式的官方编码。由于缺乏编码策略而导致的问题通常被视为用户空间问题。在Linux中，适当的语言环境支持仍然相对较新，并且仍然存在许多不完善的地方。然而，考虑到对Linux中高质量本地化支持的高度兴趣，人们可能会期望这些问题很快得到解决。

（对于那些想了解更多关于UTF-8的人，请参阅这个FAQ或RFC 3629）。
