# Wayland架构

了解 wayland 架构以及它与 X 有何不同的一个好方法，就是从输入设备开始跟踪一个事件，直到它影响的变化出现在屏幕上。

## X 与 Wayland架构

我们已知的x事件如下传递：

![](img/x-architecture.png)

1. 内核从输入设备获取事件，并通过 evdev 输入驱动程序发送给 X。内核通过驱动设备将不同设备的特定事件协议转换为标准的 Linux evdev 输入事件。
2. X 服务器会确定该事件会影响哪个窗口(一般是当前焦点窗口)，并将其发送给在该窗口上触发了相关事件的客户端。X 服务器实际上并不知道如何正确地完成这项工作，因为窗口在屏幕上的位置是由合成器(或者说窗口管理器)控制的，并可能以 X 服务器无法理解的多种方式（缩放、旋转、摇摆等）进行变换。
3. 客户端查看事件并决定要做什么。通常情况下，用户界面必须根据事件做出改变--可能是点击了一个复选框，或者指针进入了一个必须高亮显示的按钮。因此，客户端会向 X 服务器发送渲染请求。
4. X 服务器收到渲染请求后，会将其发送给驱动程序，让它对硬件进行编程以完成渲染。X 服务器还会计算渲染的边界区域，并将其作为 damage 事件发送给合成器。
5. damage 事件会告诉合成器该窗口发生了变化，它必须重新合成该窗口所在的屏幕部分。合成器负责根据其场景图和 X 窗口的内容渲染整个屏幕的内容。然而，它必须通过 X 服务器来渲染。
6. X 服务器接收到来自合成器的渲染请求，然后将合成器的后缓冲区复制到前缓冲区，或者进行翻页。在一般情况下，X 服务器必须执行这一步骤，以便考虑重叠窗口（可能需要剪切），并确定是否可以翻页。然而，对于始终全屏的合成器来说，这又是一次不必要的上下文切换。

如上所述，这中渲染过程存在一些问题。X 服务器不具备决定哪个窗口应接收事件的信息，也无法将屏幕坐标转换为窗口本地坐标。尽管 X 已将最终绘制屏幕的责任移交给了合成管理器，但 X 仍控制着前端缓冲区和模式设置。X 服务器过去需要处理的大部分复杂问题，现在都可以在内核或自带库中找到（KMS、evdev、mesa、fontconfig、freetype、cairo、Qt 等）。总的来说，X 服务器现在只是一个中间人，在应用程序和编译器之间多了一个步骤，在编译器和硬件之间多了一个步骤。

在 wayland 中，合成器是显示服务器。我们将 KMS 和 evdev 的控制权移交给合成器。wayland 协议允许合成器直接向客户端发送输入事件，并允许客户端直接向合成器发送damage事件： 

![](img/wayland-architecture.png)

1. 内核获取事件并将其发送给合成器。这与 X 的情况类似，非常好，因为我们可以重用内核中的所有输入驱动程序。
2. 合成器通过场景图来确定哪个窗口应该接收事件。场景图与屏幕上的内容相对应，而合成器可以理解应用于场景图中元素的变换。因此，合成器可以选择正确的窗口，并通过应用逆变换将屏幕坐标转换为窗口本地坐标。只要合成器能计算输入事件的逆变换，那么可应用于窗口的变换类型就会受到限制。
3. 在 X 的情况下，客户端收到事件后会更新 UI 作为响应。但在 wayland 案例中，渲染是在客户端进行的，客户端只需向合成器发送一个请求，指出更新的区域。
4. 合成器从客户端收到 damage 事件，然后重新合成屏幕。然后，合成器可以直接发出 ioctl，与 KMS 一起安排翻页。

## Wayland渲染

在上述概述中，我忽略了一个细节，那就是客户端在 wayland 下的实际渲染方式。通过移除 X 服务器，我们也移除了 X 客户端通常使用的渲染机制。不过，我们已经在 X 下的 DRI2 中使用了另一种机制：直接渲染。通过直接渲染，客户端和服务器共享一个视频内存缓冲区。客户端链接到一个渲染库（如：OpenGL），该库知道如何对硬件进行编程，并直接在缓冲区中进行渲染。反过来，合成器在合成桌面时，可以将缓冲区用作纹理。初始设置完成后，客户端只需告诉合成器使用哪个缓冲区，以及何时何地将新内容渲染到缓冲区中。

这样，应用程序就有两种更新窗口内容的方法：
1. 将新内容渲染到一个新的缓冲区中，并告诉合成器使用该缓冲区代替旧缓冲区。应用程序可以在每次需要更新窗口内容时分配一个新的缓冲区，也可以保留两个（或更多）缓冲区并在它们之间循环使用。缓冲区管理完全由应用程序控制。
2. 将新内容渲染到上次告诉合成器使用的缓冲区中。虽然可以直接渲染到与合成器共享的缓冲区中，但这可能会与合成器发生竞争。可能发生的情况是，重新绘制窗口内容可能会被合成器重新绘制桌面所中断。如果应用程序在清空窗口后、渲染内容前被中断，合成器将从空白缓冲区进行纹理绘制。其结果是，应用程序窗口将在空白窗口或半渲染内容之间闪烁。避免这种情况的传统方法是将新内容渲染到后置缓冲区，然后从后置缓冲区复制到合成器表面。后置缓冲区可以即时分配，其大小足以容纳新内容，应用程序也可以保留一个缓冲区。同样，这也是由应用程序控制的。

无论是哪种情况，应用程序都必须告诉合成器曲面的哪个区域有新内容。当应用程序直接渲染到共享缓冲区时，合成器需要注意到有新内容。但同样在交换缓冲区时，合成器不会认为有任何变化，它需要应用程序发出请求后才会重新绘制桌面。我们的想法是，即使应用程序向合成器传递了新的缓冲区，缓冲区中也可能只有一小部分内容是不同的，例如闪烁的光标。

## Wayland硬件支持

通常，硬件支持包括modesetting/display和EGL/GLES2。除此之外，Wayland 还需要一种在进程间有效共享缓冲区的方法。这涉及Wayland客户端和服务器端。

在客户端，我们定义了一个 Wayland EGL 平台。在 EGL 模型中，它包括本地类型（EGLNativeDisplayType、EGLNativeWindowType 和 EGLNativePixmapType）以及创建这些类型的方法。换句话说，它是将 EGL 栈及其缓冲区共享机制与通用 Wayland API 绑定在一起的胶水代码。EGL 堆栈有望提供 Wayland EGL 平台的实现。完整的 API 位于 `wayland-egl.h` 头文件中。mesa EGL 栈的开源实现在 `platform_wayland.c` 中。

EGL 协议栈将定义一个特定于供应商的协议扩展，让客户端 EGL 协议栈与合成器交流缓冲区细节，以共享缓冲区。`wayland-egl.h` API 的目的是将其抽象化，让客户端为 Wayland 表面创建 EGLSurface 并开始渲染。开源堆栈使用 drm Wayland 扩展，让客户端发现要使用的 drm 设备并进行验证，然后与合成器共享 drm (GEM) 缓冲区。

Wayland 的服务器端是垂直领域的合成器和核心UX，通常将任务切换器、应用启动器和锁屏集成在单个应用中。服务器在modsetting应用程序接口（内核modsetting、OpenWF Display 或类似应用程序接口）之上运行，并使用 EGL/GLES2 合成器和硬件叠加（如有）混合合成最终用户界面。启用modsetting、EGL/GLES2 和overlays应该是标准硬件设置的一部分。启用 Wayland 的额外要求是 `EGL_WL_bind_wayland_display` 扩展，它允许合成器从通用的 Wayland 共享缓冲区创建 EGLImage。它类似于 `EGL_KHR_image_pixmap` 扩展，可以从 X pixmap创建 EGLImage。

该扩展有一个设置步骤，需要将 EGL 显示器绑定到 Wayland 显示器。然后，当合成器从客户端接收通用的 Wayland 缓冲区时（通常是在客户端调用 eglSwapBuffers 时），它就能将 `struct wl_buffer` 指针作为 `EGLClientBuffer` 参数传递给 `eglCreateImageKHR`，并将 `EGL_WAYLAND_BUFFER_WL` 作为目标。这将创建一个 `EGLImage`，然后合成器可将其用作纹理，或传递给模式设置代码用作叠加平面。同样，这也是由厂商特定的协议扩展实现的，服务器端将接收共享缓冲区的驱动程序特定细节，并在用户调用 `eglCreateImageKHR` 时将其转化为 EGL 图像。

